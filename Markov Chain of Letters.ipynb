{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Selen Parlar\n",
    "\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr?gr?mm?ng?H?m?w?rk\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0.0002835\n",
      "b 0.0228302\n",
      "c 0.0369041\n",
      "d 0.0426290\n",
      "e 0.0012216\n",
      "f 0.0075739\n",
      "g 0.0171385\n",
      "h 0.0014659\n",
      "i 0.0372661\n",
      "j 0.0002353\n",
      "k 0.0110124\n",
      "l 0.0778259\n",
      "m 0.0260757\n",
      "n 0.2145354\n",
      "o 0.0005459\n",
      "p 0.0195213\n",
      "q 0.0001749\n",
      "r 0.1104770\n",
      "s 0.0934290\n",
      "t 0.1317960\n",
      "u 0.0098029\n",
      "v 0.0306574\n",
      "w 0.0088799\n",
      "x 0.0009562\n",
      "y 0.0233701\n",
      "z 0.0018701\n",
      ". 0.0715219\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open(r'C:\\Users\\parla\\Desktop\\Master\\CMPE 547\\transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "    print(c,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given NN, write a program to sample random strings with letters  x1,x2,…,xNx1,x2,…,xN from p(x1:N|x0)p(x1:N|x0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet$ Convert string into a list and normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_list = []\n",
    "for t in T:# Transitions\n",
    "    tf = [float(i) for i in t]\n",
    "    sum_t = sum(tf)\n",
    "    tf_ = [i/sum_t for i in tf]\n",
    "    T_list.append(tf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a sample string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(N):\n",
    "    # Initial string as mentioned above.\n",
    "    text = \".\"\n",
    "    for i in range(N):\n",
    "        char = np.random.choice(alphabet, 1, p=T_list[letter2idx[text[i]]])\n",
    "        text = text + char[0]\n",
    "    print(text[1 : len(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiskins.icerd.ouge.ith.itos.trass.hernof..t.airove\n"
     ]
    }
   ],
   "source": [
    "generate_sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample missing letters conditioned on observed ones from p(x−α|xα)p(x−α|xα)  where  αα  denotes indices of observed letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_missing_letters(trials):    \n",
    "    for ts in test_strings:\n",
    "        print(\"Initial: \" + ts)\n",
    "        for t in range(trials):\n",
    "            text = ''\n",
    "            for i in range(len(ts)):\n",
    "                # As mentioned, unknown chars given as _ or ?\n",
    "                if(i == 0 and (ts[i] == '_' or ts[i] == '?')):\n",
    "                    char = np.random.choice(alphabet, 1, p=T_list[letter2idx['.']])\n",
    "                    text = text + char[0] \n",
    "                elif(ts[i] != '_' and ts[i] != '?'):\n",
    "                    text = text + ts[i]\n",
    "                else:\n",
    "                    char = np.random.choice(alphabet, 1, p=T_list[letter2idx[text[i-1]]])\n",
    "                    text = text + char[0] \n",
    "            print(\"Sample \" + str(t) + \": \" + text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: th__br__n.f_x.\n",
      "Sample 0: thedbratn.fox.\n",
      "Sample 1: the.brann.fox.\n",
      "Sample 2: thacbradn.f.x.\n",
      "Sample 3: thtebre.n.fux.\n",
      "Sample 4: thatbrven.f.x.\n",
      "Sample 5: thetbrwin.f.x.\n",
      "Sample 6: thi.brisn.f.x.\n",
      "Sample 7: the.brt.n.f.x.\n",
      "Sample 8: th.ebrshn.fox.\n",
      "Sample 9: therbr.tn.fox.\n",
      "\n",
      "Initial: _u_st__n_.to_be._nsw_r__\n",
      "Sample 0: ounst.lnt.to.be.onswerel\n",
      "Sample 1: mucsth.no.tonbe.wnsworr.\n",
      "Sample 2: ousstrin..toube.inswirgu\n",
      "Sample 3: sulsturne.toobe.gnsw.re.\n",
      "Sample 4: ou.sthina.torbe.snswnrof\n",
      "Sample 5: cumsthend.to.be.lnswaris\n",
      "Sample 6: murst.on..tombe.fnsw.rl.\n",
      "Sample 7: au.stoun..tonbe.dnswhres\n",
      "Sample 8: sutstheno.tovbe.onswirin\n",
      "Sample 9: hu.stedn..to.be.tnswarec\n",
      "\n",
      "Initial: i__at_._a_h_n_._e_r_i_g\n",
      "Sample 0: itiath.uanhint.oedreisg\n",
      "Sample 1: in.atu.aamheng.ieer.itg\n",
      "Sample 2: in.atr.wacheni.aefreing\n",
      "Sample 3: i.aati.sash.n..aeprpi.g\n",
      "Sample 4: i.wati.darh.nd.ge.r.isg\n",
      "Sample 5: in.atl.valh.ne.ae.rdimg\n",
      "Sample 6: ithati.ianhons.iedr.ing\n",
      "Sample 7: is.ata.sathanf.yedraing\n",
      "Sample 8: ithat..harh.no.ve.rding\n",
      "Sample 9: i.tat..lapheno.iexreing\n",
      "\n",
      "Initial: q___t.___z._____t.__.___.__.\n",
      "Sample 0: que.t.l.wz.anfiot.d..hut.s..\n",
      "Sample 1: qur.t.aliz.mouret.ng.t.w.mp.\n",
      "Sample 2: qulot.d.tz.ofotht.s..ded.t..\n",
      "Sample 3: qur.t.thiz.whe.tt.re.ste.ou.\n",
      "Sample 4: qugut.thaz.or.int.r..ith.sh.\n",
      "Sample 5: qurot.acrz.s.atht.ir.her.to.\n",
      "Sample 6: qurst.d.lz.hove.t.or.ond.th.\n",
      "Sample 7: qusat.ly.z.im.ttt..w.oil.be.\n",
      "Sample 8: quset.kigz.thavit.rs.t.i.ce.\n",
      "Sample 9: qur.t.mesz.d.adit.in.ply.t..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_sample_missing_letters(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the gaps by estimating the most likely letter for each position. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet$ Since it is a Markov(1) Model, just taking the most probable letter one by one from its previous distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample_missing_letters_by_likelihood():    \n",
    "    for ts in test_strings:\n",
    "        print(\"Initial: \" + ts)\n",
    "        text = ''\n",
    "        probabilities = []\n",
    "        for t in range(len(ts)):\n",
    "            sum_tf = 0\n",
    "            if(t == 0 and (ts[t] == '_' or ts[t] == '?')):\n",
    "                char = alphabet[np.argmax(T_list[letter2idx['.']])]\n",
    "                text = text + char\n",
    "                for tf in T_list:\n",
    "                    sum_tf = sum_tf + tf[letter2idx['.']]                \n",
    "                probabilities.append(sum_tf* T_list[letter2idx['.']][letter2idx[char]])\n",
    "            elif(ts[t] != '_' and ts[t] != '?'):\n",
    "                text = text + ts[t]\n",
    "            else:\n",
    "                char = alphabet[np.argmax(T_list[letter2idx[text[t-1]]])]\n",
    "                text = text + char\n",
    "                for tf in T_list:\n",
    "                    sum_tf = sum_tf + tf[letter2idx[text[t-1]]]\n",
    "                probabilities.append(sum_tf* T_list[letter2idx['.']][letter2idx[char]])\n",
    "        print(\"BestFit:  \" + text)\n",
    "        mpy = 1\n",
    "        for i in probabilities:\n",
    "            mpy = mpy * i\n",
    "        print(\"log-probability: \" + str(math.log(mpy)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: th__br__n.f_x.\n",
      "BestFit:  the.bre.n.f.x.\n",
      "log-probability: -14.484936467679942\n",
      "\n",
      "Initial: _u_st__n_.to_be._nsw_r__\n",
      "BestFit:  tursthen..tonbe.tnswhre.\n",
      "log-probability: -25.87153701236817\n",
      "\n",
      "Initial: i__at_._a_h_n_._e_r_i_g\n",
      "BestFit:  in.ath.tanhen..te.reing\n",
      "log-probability: -27.103898703727463\n",
      "\n",
      "Initial: q___t.___z._____t.__.___.__.\n",
      "BestFit:  quret.thez.the.tt.th.the.th.\n",
      "log-probability: -43.316453184443915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_sample_missing_letters_by_likelihood()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to improve the model to get better estimations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet$ One can use the higher order Markov Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
